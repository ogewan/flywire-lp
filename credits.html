<!DOCTYPE html>
<html lang="en">

<head>
  <link href="bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <script>
    $(function () {
      $("#navbar").load("navbar.html");
      $("head").load("head.html");
    });
  </script>
</head>

<body style='background:black; color: white'>
  <span id="navbar"></span>

  <div class="container">
    <div class="pt-2 my-md-2 pt-md-1">
      <h1>Credits</h1>
      <p>To publish data from FlyWire, please see instructions <a
          href='https://docs.google.com/document/d/1bUkOB-5JnT3u__JDvAoVDHJ3zr5NXQtV_63yx2w6Tcc/edit?usp=sharing'>here</a>.
      </p>
      <p>Scientific publications derived in whole or in part from use of FlyWire should cite our paper, <a
          href='https://www.nature.com/articles/s41592-021-01330-0.pdf?proof=t'>Dorkenwald et al. 2021</a>
        and the website, <a href='http://flywire.ai/'>flywire.ai</a>. </p>
      <p>Please also add Acknowledgments: the Princeton FlyWire team and members of the Murthy and Seung labs for
        development and
        maintenance of FlyWire (supported by BRAIN Initiative grant MH117815 to Murthy and Seung).</p>
      <p></p>FlyWire is based on EM image data that was
      released by <a href='https://www.cell.com/cell/fulltext/S0092-8674(18)30787-6'>Zheng, Lauritzen et al. 2018</a>
      under a
      <a href='http://creativecommons.org/licenses/by-nc/4.0/'>CC-BY-NC 4.0 International license</a>, so this paper
      should also be cited in scientific publications. Data
      generated by
      FlyWire will be made publicly available to the scientific community, in accordance with FlyWire Principles. The
      segmentation approach is adapted from our earlier work, <a href='https://arxiv.org/abs/1706.00120'>Lee et al.
        2017.</a>
      </p>

      <p>Principal investigators: Sebastian Seung and Mala Murthy</p>

      <p>Director of Operations and Community: Claire McKellar</p>

      <p>Alignment: Thomas Macrina, Nico Kemnitz, Barak Nehoran, Sergiy Popovych, Zhen Jia, Eric Mitchell, Kai Li</p>

      <p>Design: Amy Sterling, Claire McKellar, Oluwaseun Ogedengbe, Chris Jordan, Marissa Sorek, Celia David, Devon
        Jones,
        Kai Kuehner, James Hebditch</p>

      <p>Segmentation: Kisuk Lee, Ran Lu, Jingpeng Wu</p>

      <p>Synapses: imported from the work of <a href='https://www.nature.com/articles/s41592-021-01183-7'>Buhmann et al.
          2021</a>. For using the
        “cleft_score” please also cite
        <a href='https://link.springer.com/chapter/10.1007%2F978-3-030-00934-2_36'>Heinrich et al.
          2018</a>. Transmitter predictions from <a
          href='https://www.biorxiv.org/content/10.1101/2020.06.12.148775v1'>Eckstein et al. 2020</a>, with
        infrastructure contributed by Davi Bock,
        Gregory
        Jefferis
        and Eric Perlman. The prediction and dissemination of the neurotransmitter information was supported by NIH
        BRAIN
        Initiative (grant 1RF1MH120679-01); additional work including assembling ground truth data was also supported by
        Wellcome trust (203261/Z/16/Z).
      </p>

      <p>Proofreading platform: Sven Dorkenwald, Nico Kemnitz, Chris Jordan, Forrest Collman, William Silversmith,
        Manuel Castro, Akhilesh Halageri,
        Oluwaseun Ogedengbe, Jonathan Zung, Kai Kuehner, Casey Schneider-Mizell, FlyWire's frontend is an adapted fork
        of
        Neuroglancer by Jeremy Maitin-Shepard at Google.</p>

      <p>Training material: Claire McKellar, Diego Pacheco, Shruthi Ravindranath, Kathi Eichler</p>

      <p>Proofreading testers: Austin Burke, Jay Gager, James Hebditch, Selden Koolman, Merlin Moore, Sarah Morejohn,
        Ben Silverman, Kyle Willie, Ryan Willie, and Murthy Lab</p>

      <p>Annotation infrastructure (CAVE): Forrest Collman, Sven Dorkenwald, Casey Schneider-Mizell, Derrick Brittain,
        Chris
        Jordan</p>

      <p>Ground truth annotation: Szi-chieh Yu, Seung lab tracing team. The ground truth data are available <a
          href="https://zenodo.org/record/5748891#.Ye7xr_7MJPY">here.</a< /p>

          <p>Image acquisition: <a
              href='https://www.cell.com/cell/fulltext/S0092-8674(18)30787-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867418307876%3Fshowall%3Dtrue'>Zheng
              et al. 2018.</a></p>

          <p>Montaging: Eric Trautman, Stephan Saalfeld</p>

          <p>Funding: NIH BRAIN Initiative RF1 MH117815-01 & Intelligence Advanced Research Projects Activity (IARPA)
            via
            Department of
            Interior/ Interior Business Center (DoI/IBC) contract numbers D16PC00003, D16PC00004, and D16PC0005.
            Disclaimer:
            The
            views and conclusions contained herein are those of the authors and should not be interpreted as necessarily
            representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/IBC, or the
            U.S.
            Government. Additional support from the Mathers Foundation, as well as assistance from Google and Amazon.
          </p>

          <p>With additional thanks to all the members of the Seung and Murthy labs, and the staff of Eyewire.</p>
    </div>
  </div>

</body>

</html>